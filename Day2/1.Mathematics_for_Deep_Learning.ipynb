{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ST8QJlxSdvMU",
    "outputId": "7eae7c44-6007-47b5-bd59-cb4ca1df832c"
   },
   "outputs": [],
   "source": [
    "#@title Imports { display-mode: \"form\" }\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# try:\n",
    "#   tf.enable_eager_execution()\n",
    "#   print('Eager execution enabled')\n",
    "# except ValueError:\n",
    "#   print('Already running in Eager mode')\n",
    "\n",
    "# tfe = tf.contrib.eager # DEPRECATED\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgFS1eZOdws_"
   },
   "source": [
    "## Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "E0TdsagndySr",
    "outputId": "535c541c-da43-4154-dae9-7198ba1e9ed0"
   },
   "outputs": [],
   "source": [
    "# Define matrix A\n",
    "A = np.array(\n",
    "  [[1.0, 3.0],\n",
    "   [2.0, 1.0],\n",
    "   [4.0, 2.0]]\n",
    ")\n",
    "\n",
    "# Define matrix B\n",
    "B = np.array(\n",
    "  [[6.0, 2.0, 1.0],\n",
    "   [3.0, 4.0, 5.0]]\n",
    ")\n",
    "\n",
    "# Define vector x\n",
    "x = np.array([3.0, 2.0])\n",
    "\n",
    "print('A.shape is:', A.shape, 'B.shape is:', B.shape, 'x.shape is:', x.shape)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xVzrzTskHqK"
   },
   "source": [
    "### Matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ySFMEkRrkJ51",
    "outputId": "f52ddad3-c34a-4a07-8ec4-8682e1abcc4e"
   },
   "outputs": [],
   "source": [
    "# Using numpy dot\n",
    "y = A.dot(x)\n",
    "\n",
    "print('Using dot:\\t y =', y, '\\t y.shape =', y.shape)\n",
    "\n",
    "# Using einsum\n",
    "y = np.einsum('ij, j', A, x)\n",
    "\n",
    "print('Using einsum:\\t y =', y, '\\t y.shape =', y.shape)\n",
    "\n",
    "# Manual version 1\n",
    "y = np.array([\n",
    "    A[0,0] * x[0] + A[0,1] * x[1],\n",
    "    A[1,0] * x[0] + A[1,1] * x[1],\n",
    "    A[2,0] * x[0] + A[2,1] * x[1],\n",
    "    ])\n",
    "print('Manual 1:\\t y =', y, '\\t y.shape =', y.shape)\n",
    "\n",
    "# Manual version 2: \n",
    "# Matrix-vector multiplication can be thought of as a linear combination of the columns of of the matrix\n",
    "y = x[0] * A[:,0]  +  x[1] * A[:, 1]\n",
    "\n",
    "print('Manual 2:\\t y =', y, '\\t y.shape =', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXfRCQfglg7Y"
   },
   "source": [
    "### Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "CCw3o6GMeD1o",
    "outputId": "8f963951-8502-4b13-b858-fce70e4c6538"
   },
   "outputs": [],
   "source": [
    "# Using numpy dot\n",
    "C = A.dot(B)\n",
    "\n",
    "print('Using DOT: C= \\n\\n', C, '\\n\\nC.shape =', C.shape)\n",
    "\n",
    "# Using einsum\n",
    "C = np.einsum('ik, kj', A, B)\n",
    "print('\\n\\nUsing einsum: C= \\n\\n', C, '\\n\\nC.shape =', C.shape)\n",
    "\n",
    "# Note, the above einsum notation is equivalent to the following\n",
    "C = np.einsum('ik, kj -> ij', A, B)\n",
    "\n",
    "# And in Tensorflow\n",
    "C = tf.matmul(A, B)\n",
    "print('\\n\\nUsing Tensorflow: C= \\n\\n', C, '\\n\\nC.shape =', C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o3U0Fc7mlxSd"
   },
   "source": [
    "Matrix multiplication is not commutative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "iiI6J7ZDj9Fl",
    "outputId": "1c0e575f-1b2c-4da6-aab1-7f1e5ed60f19"
   },
   "outputs": [],
   "source": [
    "# Matrix multiplication is not commutative:\n",
    "C = B.dot(A)\n",
    "print('C: \\n', C)\n",
    "print()\n",
    "print('C.shape:', C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WxJ0muOj34SB"
   },
   "source": [
    "## Computing gradients with TensorFlow\n",
    "$y = Ax$\n",
    "\n",
    "In the code below, we use Tensorflow to calculate the following derivatives:\n",
    "\n",
    "$\\frac{dy}{dx}$ \n",
    "\n",
    "and \n",
    "\n",
    "$\\frac{\\partial y}{\\partial A}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "5wCGTn1s3zlV",
    "outputId": "2b250cbe-4c07-481d-ecf9-ed8d449cf921"
   },
   "outputs": [],
   "source": [
    "A_tensor = tf.Variable(A)\n",
    "x_tensor = tf.Variable(x)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = tf.einsum('ij,j', A_tensor, x_tensor)\n",
    "\n",
    "dydx, dydA = tape.gradient(y, [x_tensor, A_tensor])\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print()\n",
    "print('dy/dA =', dydA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btAykJ_oEZ-i"
   },
   "source": [
    "# Neural Network Gradient Example\n",
    "In the following example, we compute the output of a 1 layer neural network and the gradients with respect to its parameters. We define an example input vector and parameters, but keep the computation generic. You can change the values and shapes of x, A and b below and run the rest of the code to compute the output and gradients for your own example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRnif1ZP4kYQ"
   },
   "outputs": [],
   "source": [
    "x = np.array([[-1.], [0.1], [2.1]])  # X has shape (3, 1)\n",
    "A = np.array([              # A has shape (2, 3)\n",
    "    [ 1.1, -2.5,  0.3],\n",
    "    [-2.1,  0.2, -1.1]\n",
    "])  \n",
    "b = np.array([[-1.0], [2.0]])      # b has shape (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaTm7-r9FBxl"
   },
   "source": [
    "Compute the neural network output\n",
    "$\\mathbf{f} = \\operatorname{tanh}(A\\mathbf{x} + \\mathbf{b})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1HR6uCTjFAvV",
    "outputId": "ff5beb67-d370-4a70-a8ee-b6c4b64a585e"
   },
   "outputs": [],
   "source": [
    "M, N = A.shape\n",
    "z = A.dot(x) + b\n",
    "f = np.tanh(z)\n",
    "\n",
    "print('f =', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQKVQ13jGkIH"
   },
   "source": [
    "Compute the partial derivatives:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d\\mathbf{f}}{d\\mathbf{z}} ; \\frac{\\partial\\mathbf{z}}{\\partial\\mathbf{x}} ; \\frac{\\partial\\mathbf{z}}{\\partial\\mathbf{b}} ; \\frac{\\partial\\mathbf{z}}{\\partial\\mathbf{A}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "sJF9p5lHE4Z_",
    "outputId": "3900b59e-ab3d-4f9d-caa4-dd79c7fd49c6"
   },
   "outputs": [],
   "source": [
    "# partial derivatives\n",
    "dfdz = 1-f**2       # (derivative of tanh is 1-tanh^2)\n",
    "print('df/dz =', dfdz, '\\nshape:', dfdz.shape)\n",
    "print()\n",
    "\n",
    "dzdx = A\n",
    "print('dz/dx =\\n', dzdx, '\\n\\nshape:', dzdx.shape)\n",
    "print()\n",
    "\n",
    "dzdb = np.eye(M)\n",
    "print('dz/db =\\n', dzdb, '\\n\\nshape:', dzdb.shape)\n",
    "print()\n",
    "\n",
    "dzdA = np.zeros((M, M, N))  # Start with a tensor of zeros of the correct shape\n",
    "for i in range(M):          # Then set the diagonal elements of dzdA\n",
    "  dzdA[i,i,:] = x.T  \n",
    "\n",
    "print('dz/dA =\\n', dzdA, '\\n\\nshape:', dzdA.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gcw6bNirweZl"
   },
   "source": [
    "Finally, we compute the gradients of the neural network output $f$ with respect to the parameters $A$ and $\\mathbf{b}$ and the input $\\mathbf{x}$ using the chain rule:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}} &= \\frac{d \\mathbf{f}}{d \\mathbf{z}} \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}} \\ ; \\ \n",
    "\\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{b}} = \\frac{d \\mathbf{f}}{d \\mathbf{z}} \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{b}} \\ ; \\ \n",
    "\\frac{\\partial \\mathbf{f}}{\\partial A} = \\frac{d \\mathbf{f}}{d \\mathbf{z}} \\frac{\\partial \\mathbf{z}}{\\partial A} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "o22q4uljzbpR",
    "outputId": "c07b47af-c680-4e0a-ef47-f9bf921a8346"
   },
   "outputs": [],
   "source": [
    "dfdx = np.einsum('il, lj', dfdz, dzdx)\n",
    "print('df/dx =\\n', dfdx, '\\n\\nshape:', dfdx.shape)\n",
    "print()\n",
    "\n",
    "dfdb = np.einsum('il, lj', dfdz, dzdb)\n",
    "print('df/db =\\n', dfdb, '\\n\\nshape:', dfdb.shape)\n",
    "print()\n",
    "\n",
    "dfdA = np.einsum('il, ljk', dfdz, dzdA)\n",
    "print('df/dA =\\n', dfdA, '\\n\\nshape:', dfdA.shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mathematics for Machine Learning Examples",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
